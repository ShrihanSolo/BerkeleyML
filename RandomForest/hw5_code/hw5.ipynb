{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61da9723-5949-47ef-a6e6-633943d7102b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08264b45-f4d0-476c-a5de-6f1b4eec8bee",
   "metadata": {},
   "source": [
    "### Q3.1\n",
    "Cleaning and preprocessing (SPAM). The majority of the decision tree is implemented in the decision tree starter file, and imported. I set the seed as 42, load the spam file and re-save a shuffled and split version of it. Then I reload the new version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1491,
   "id": "8b23c949-6d12-48a6-b8bf-778f4dbd805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "def load_and_save(filename, path, num = None, percent = None):\n",
    "    \"\"\"\n",
    "    Shuffles, splits and adds the modified data to a new file,\n",
    "    prepended with 'prep_'.\n",
    "    \"\"\"\n",
    "    dataset = io.loadmat(path+filename)\n",
    "    if percent:\n",
    "        num = int(dataset[\"training_labels\"].shape[0] * percent)\n",
    "    t_dat, t_lbl, v_dat, v_lbl = split_data(dataset[\"training_data\"], \n",
    "                                            dataset[\"training_labels\"],\n",
    "                                            num)\n",
    "    dataset[\"training_data\"] = t_dat\n",
    "    dataset[\"training_labels\"] = t_lbl\n",
    "    dataset[\"valid_data\"] = v_dat\n",
    "    dataset[\"valid_labels\"] = v_lbl\n",
    "    \n",
    "    io.savemat(path + \"prep_\" + filename, dataset)\n",
    "\n",
    "def split_data(train, labels, num_valid):\n",
    "    num_data = train.shape[0]\n",
    "    assert num_valid <= len(train)\n",
    "    assert num_data == labels.shape[0]\n",
    "    idx = np.arange(num_data)\n",
    "    np.random.shuffle(idx)\n",
    "    train_shf = train[idx]\n",
    "    lbl_shf = labels[idx]\n",
    "    valid_dat = train_shf[:num_valid]\n",
    "    valid_lbl = lbl_shf[:num_valid]\n",
    "    train_dat = train_shf[num_valid:]\n",
    "    train_lbl = lbl_shf[num_valid:]\n",
    "    return train_dat, train_lbl, valid_dat, valid_lbl\n",
    "\n",
    "def contrast_norm(td):\n",
    "    return np.array([td[i] / np.linalg.norm(td[i]) for i in range(len(td))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "ab69c86d-264a-45e3-bcab-ade8cb22fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_and_save(\"spam_data.mat\", \"datasets/spam_data/\", percent = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888e91d-c2ee-4e8c-b4e8-02592954e851",
   "metadata": {},
   "source": [
    "Cleaning and preprocessing (Titanic). The majority of the decision tree is implemented in the decision tree starter file, and imported. I set the seed as 42, load the .csv file. The function below then creates a new .mat file in the same folder, and draws the dataset from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1477,
   "id": "7db42caa-4021-44c1-8efe-ba7d8b3ff0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def saveTitanic(num = None, percent = None):\n",
    "    \"\"\"\n",
    "    Shuffles, splits and adds the modified data to a new file,\n",
    "    prepended with 'prep_'.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(\"datasets/titanic/titanic_training.csv\") as f:\n",
    "        dr = csv.DictReader(f)\n",
    "        dictlist = []\n",
    "        y = []\n",
    "        for idict in dr:\n",
    "            if idict[\"survived\"] == '':\n",
    "                continue\n",
    "            y.append(idict[\"survived\"])\n",
    "            idict.pop(\"survived\")\n",
    "            for k in idict:\n",
    "                if idict[k] == '':\n",
    "                    idict[k] = np.nan\n",
    "            idict[\"pclass\"] = float(idict[\"pclass\"])\n",
    "            idict[\"sibsp\"] = float(idict[\"sibsp\"])\n",
    "            idict[\"parch\"] = float(idict[\"parch\"])\n",
    "            idict[\"fare\"] = float(idict[\"fare\"])\n",
    "            idict[\"age\"] = float(idict[\"age\"])\n",
    "            dictlist.append(idict)\n",
    "        train_size = len(dictlist)\n",
    "    \n",
    "    with open(\"datasets/titanic/titanic_testing_data.csv\") as f:\n",
    "        dr2 = csv.DictReader(f)\n",
    "        dictlist2 = []\n",
    "        for idict in dr2:\n",
    "            for k in idict:\n",
    "                if  idict[k] == '':\n",
    "                    idict[k] = np.nan\n",
    "            idict[\"pclass\"] = float(idict[\"pclass\"])\n",
    "            idict[\"sibsp\"] = float(idict[\"sibsp\"])\n",
    "            idict[\"parch\"] = float(idict[\"parch\"])\n",
    "            idict[\"fare\"] = float(idict[\"fare\"])\n",
    "            idict[\"age\"] = float(idict[\"age\"])\n",
    "            dictlist2.append(idict)\n",
    "        test_size = len(dictlist2)\n",
    "    \n",
    "    dlfinal = dictlist + dictlist2\n",
    "    dv = DictVectorizer(sparse = False)\n",
    "    X = dv.fit_transform(dlfinal)\n",
    "    feature_labels = dv.get_feature_names_out()\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    X = imp.fit_transform(X)\n",
    "    y = np.array(y, dtype = int)\n",
    "    X2 = X[train_size:]\n",
    "    X = X[:train_size]\n",
    "\n",
    "    dataset = io.loadmat(\"datasets/spam_data/spam_data.mat\")\n",
    "    \n",
    "    if percent:\n",
    "        num = int(y.shape[0] * percent)\n",
    "        \n",
    "    t_dat, t_lbl, v_dat, v_lbl = split_data(X, \n",
    "                                            y,\n",
    "                                            num)\n",
    "    dataset[\"training_data\"] = t_dat\n",
    "    dataset[\"training_labels\"] = t_lbl\n",
    "    dataset[\"valid_data\"] = v_dat\n",
    "    dataset[\"valid_labels\"] = v_lbl\n",
    "    dataset[\"test_data\"] = X2\n",
    "    dataset[\"feature_labels\"] = feature_labels\n",
    "    \n",
    "    io.savemat(\"datasets/titanic/prep_titanic.mat\", dataset)\n",
    "\n",
    "saveTitanic(percent = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1478,
   "id": "d9a58b70-51b3-427a-8d7e-f4bbd2cdaac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tset = io.loadmat(\"datasets/titanic/prep_titanic.mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d734e-855b-4322-b064-bb5b3cf1a010",
   "metadata": {},
   "source": [
    "Spam Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1479,
   "id": "fb0b540c-87e9-4383-aac5-a2a58786363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dset[\"training_data\"]\n",
    "y = dset[\"training_labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d850c-3325-477f-8c08-dd73528631e7",
   "metadata": {},
   "source": [
    "Titanic Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1481,
   "id": "e20fad9b-ecb0-4a8b-89b6-e9ab6a4112e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = tset[\"training_data\"]\n",
    "yt = tset[\"training_labels\"]\n",
    "Xtest = tset[\"test_data\"]\n",
    "titanicftlbl = tset[\"feature_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1454,
   "id": "70fb1c15-226e-4631-adbd-9856015978a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1127)"
      ]
     },
     "execution_count": 1454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1455,
   "id": "b796a358-d222-40b6-8796-b3970e4296d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 1127)"
      ]
     },
     "execution_count": 1455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed36b1a-e4ea-4451-a830-1f2d1836e65c",
   "metadata": {},
   "source": [
    "**The implementation in decision_tree_starter.py is provided below as a reference for this question. Do not run this, the file is imported by the notebook to gain access to the relevant classes and functions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c95d9a-9bcc-4cb5-8599-e4c6bf7d5ec5",
   "metadata": {},
   "source": [
    "```# You may want to install \"gprof2dot\"\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import cross_validate\n",
    "import sklearn.tree\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "random.seed(246810)\n",
    "np.random.seed(246810)\n",
    "\n",
    "eps = 1e-5  # a small number\n",
    "\n",
    "\n",
    "# Vectorized function for hashing for np efficiency\n",
    "def w(x):\n",
    "    return np.int(hash(x)) % 1000\n",
    "\n",
    "\n",
    "h = np.vectorize(w)\n",
    "\n",
    "spam_features = [\n",
    "            \"pain\", \"private\", \"bank\", \"money\", \"drug\", \"spam\", \"prescription\",\n",
    "            \"creative\", \"height\", \"featured\", \"differ\", \"width\", \"other\",\n",
    "            \"energy\", \"business\", \"message\", \"volumes\", \"revision\", \"path\",\n",
    "            \"meter\", \"memo\", \"planning\", \"pleased\", \"record\", \"out\",\n",
    "            \"semicolon\", \"dollar\", \"sharp\", \"exclamation\", \"parenthesis\",\n",
    "            \"square_bracket\", \"ampersand\"\n",
    "        ]\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    \n",
    "    class DTNode:\n",
    "        def __init__(self, \n",
    "                     feat = None, \n",
    "                     thresh = None, \n",
    "                     left = None, \n",
    "                     right = None, \n",
    "                     label = None):\n",
    "            self.feat = feat\n",
    "            self.thresh = thresh\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.label = label\n",
    "        \n",
    "        def __str__(self, level=0):\n",
    "            if self.feat != None or self.thresh != None:\n",
    "                ret = \"\\t\"*level+repr(\"Feature x\" + str(self.feat) + \" > \" + str(self.thresh))+\"\\n\"\n",
    "            else:\n",
    "                ret = \"\\t\"*level+repr(\"Leaf Label: \" + str(self.label))+\"\\n\"\n",
    "            if self.left:\n",
    "                ret += self.left.__str__(level+1)\n",
    "            if self.right:\n",
    "                ret += self.right.__str__(level+1)\n",
    "            return ret\n",
    "\n",
    "        def __repr__(self):\n",
    "            return '<tree node representation>'\n",
    "    \n",
    "    def __init__(self, max_depth=3, feature_labels=None):\n",
    "        # TODO implement __init__ function\n",
    "        self.max_depth = max_depth\n",
    "        self.features = feature_labels\n",
    "        self.tree = None\n",
    "    \n",
    "    def create_node(self, X, y, depth = 0):\n",
    "        ent = self.entropy(y)\n",
    "        if ent == 0 or depth == self.max_depth or len(y) == 1:\n",
    "            l = max(set(y), key = (lambda x: np.count_nonzero(y == x)))\n",
    "            assert l != None\n",
    "            return self.DTNode(label = l)\n",
    "        else:\n",
    "            val, feat, thresh, ridx = self.best_split2(X, y)\n",
    "            if val < 0.001:\n",
    "                l = max(set(y), key = (lambda x: np.count_nonzero(y == x)))\n",
    "                assert l != None\n",
    "                return self.DTNode(label = l)\n",
    "            print(len(ridx), val, thresh, max(X[:, feat]), min(X[:, feat]))\n",
    "            X_l = np.delete(X, ridx, axis = 0)\n",
    "            y_l = np.delete(y, ridx)\n",
    "            assert len(y_l) != 0\n",
    "            X_r = X[ridx]\n",
    "            y_r = y[ridx]\n",
    "            assert len(y_r) != 0, str(ent) + \" \" + str(val)\n",
    "            return self.DTNode(feat = feat, \n",
    "                               thresh = thresh, \n",
    "                               left = self.create_node(X_l, y_l, depth = depth + 1), \n",
    "                               right = self.create_node(X_r, y_r, depth = depth + 1))\n",
    "    \n",
    "    def best_split(self, X, y):\n",
    "        best_infog_val = 0\n",
    "        best_infog_thresh = 0\n",
    "        best_infog_feat = 0\n",
    "        for i in range(X.shape[1]): # looping through features\n",
    "            mx = np.max(X[:, i])\n",
    "            mn = np.min(X[:, i])\n",
    "            check = np.linspace(mn, mx, 20, endpoint = False)[1:]\n",
    "            for t in check:\n",
    "                ig = self.information_gain(X, y, i, t)\n",
    "                if ig > best_infog_val:\n",
    "                    best_infog_val = ig\n",
    "                    best_infog_thresh = t\n",
    "                    best_infog_feat = i\n",
    "        \n",
    "        best_ridx = self.idx_split(X, y, best_infog_feat, best_infog_thresh)\n",
    "        \n",
    "        \n",
    "        return best_infog_val, best_infog_feat, best_infog_thresh, best_ridx\n",
    "    \n",
    "    def best_split2(self, X, y):\n",
    "        best_infog_val = 0\n",
    "        best_infog_thresh = 0\n",
    "        best_infog_feat = 0\n",
    "        for i in range(X.shape[1]): # looping through features\n",
    "            check = X[:, i][1:] - 1e-5\n",
    "            if len(check) > 20:\n",
    "                mx = np.max(X[:, i])\n",
    "                mn = np.min(X[:, i])\n",
    "                check = np.linspace(mn, mx, 20, endpoint = False)[1:]\n",
    "            for t in check:\n",
    "                ig = self.information_gain(X, y, i, t)\n",
    "                if ig > best_infog_val:\n",
    "                    best_infog_val = ig\n",
    "                    best_infog_thresh = t\n",
    "                    best_infog_feat = i\n",
    "        \n",
    "        best_ridx = self.idx_split(X, y, best_infog_feat, best_infog_thresh)\n",
    "        \n",
    "        \n",
    "        return best_infog_val, best_infog_feat, best_infog_thresh, best_ridx\n",
    "    \n",
    "\n",
    "    def information_gain(self, X, y, feat_idx, thresh):\n",
    "        ridx = self.idx_split(X, y, feat_idx, thresh)\n",
    "        y_l = np.delete(y, ridx)\n",
    "        y_r = y[ridx]\n",
    "        \n",
    "        tot = len(y)\n",
    "        num_r = len(y_r)\n",
    "        num_l = tot - num_r\n",
    "        \n",
    "        ent_b = self.entropy(y)\n",
    "        ent_l = self.entropy(y_l)\n",
    "        ent_r = self.entropy(y_r)\n",
    "        ent_avg = (num_l * ent_l + num_r * ent_r) / tot\n",
    "        \n",
    "        return ent_b - ent_avg\n",
    "\n",
    "    def entropy(self, labels):\n",
    "        freq = Counter(labels)\n",
    "        clas = np.fromiter(freq.keys(), dtype = int)\n",
    "        num = np.fromiter(freq.values(), dtype = int)\n",
    "        pc = num / np.sum(num)\n",
    "        arr = pc * np.log2(pc)\n",
    "        return -np.sum(arr)\n",
    "\n",
    "    def idx_split(self, X, y, idx, thresh):\n",
    "        \"\"\" Returns the indices which are in right node.\"\"\"\n",
    "        ftlist = X[:, idx]\n",
    "        ridx = np.where(ftlist > thresh)[0]\n",
    "        return ridx\n",
    "    \n",
    "\n",
    "    def fit(self, X, y, depth = 0):\n",
    "        self.tree = self.create_node(X, y, depth = depth)\n",
    "        return self.tree\n",
    "    \n",
    "    def get_pred(self, pt, t = None):\n",
    "        if t == None:\n",
    "            t = self.tree\n",
    "        if t.label == None:\n",
    "            if pt[t.feat] > t.thresh:\n",
    "                return self.get_pred(pt, t.right)\n",
    "            else:\n",
    "                return self.get_pred(pt, t.left)\n",
    "        else:\n",
    "            return t.label\n",
    "    \n",
    "    def trace_path_spam(self, pt, t = None):\n",
    "        if t == None:\n",
    "            t = self.tree\n",
    "        if t.label == None:\n",
    "            if pt[t.feat] > t.thresh:\n",
    "                print(spam_features[t.feat] + \" > \" + str(t.thresh))\n",
    "                return self.trace_path_spam(pt, t.right)\n",
    "            else:\n",
    "                print(spam_features[t.feat] + \" <= \" + str(t.thresh))\n",
    "                return self.trace_path_spam(pt, t.left)\n",
    "        else:\n",
    "            d = {0: \"(SPAM)\", 1: \"(HAM)\"}\n",
    "            print(\"Classified as: \" + str(t.label) + \" \" + d[t.label])\n",
    "            return t.label\n",
    "            \n",
    "\n",
    "    def predict(self, X):\n",
    "        res = np.apply_along_axis(self.get_pred, 1, X)\n",
    "        return res\n",
    "    \n",
    "    def accuracy(self, pred, actual):\n",
    "        return np.sum(actual == pred) / len(pred)\n",
    "    \n",
    "\n",
    "class BaggedTrees(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, params=None, n=200):\n",
    "        if params is None:\n",
    "            params = {}\n",
    "        self.params = params\n",
    "        self.n = n\n",
    "        self.decision_trees = [\n",
    "            sklearn.tree.DecisionTreeClassifier(random_state=i, **self.params)\n",
    "            for i in range(self.n)\n",
    "        ]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # ROTOTODO\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO implement function\n",
    "        pass\n",
    "\n",
    "\n",
    "class RandomForest(DecisionTree):\n",
    "    def __init__(self, X, y, n_sub = 200, n_trees = 10, n_subf = 10, max_depth = 3):\n",
    "        self.n_sub = n_sub\n",
    "        self.n_subf = n_subf\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "        idx = np.random.randint(0, len(y), size = n_sub)\n",
    "        self.X = X[idx]\n",
    "        self.y = y[idx]\n",
    "        return\n",
    "    \n",
    "    def best_split2(self, X, y):\n",
    "        best_infog_val = 0\n",
    "        best_infog_thresh = 0\n",
    "        best_infog_feat = 0\n",
    "        feats = range(X.shape[1])\n",
    "        remf = np.random.choice(feats, size = self.n_subf)\n",
    "        for i in remf: # looping through features\n",
    "            check = X[:, i][1:] - 1e-5\n",
    "            if len(check) > 20:\n",
    "                mx = np.max(X[:, i])\n",
    "                mn = np.min(X[:, i])\n",
    "                check = np.linspace(mn, mx, 20, endpoint = False)[1:]\n",
    "            for t in check:\n",
    "                ig = self.information_gain(X, y, i, t)\n",
    "                if ig > best_infog_val:\n",
    "                    best_infog_val = ig\n",
    "                    best_infog_thresh = t\n",
    "                    best_infog_feat = i\n",
    "        best_ridx = self.idx_split(X, y, best_infog_feat, best_infog_thresh)\n",
    "        \n",
    "        \n",
    "        return best_infog_val, best_infog_feat, best_infog_thresh, best_ridx\n",
    "    \n",
    "    def fit(self, depth = 0):\n",
    "        for i in tqdm(range(self.n_trees)):\n",
    "            self.trees.append(self.create_node(self.X, self.y, depth = depth))\n",
    "        return self.trees\n",
    "    \n",
    "    def predict(self, X):\n",
    "        tot = 0\n",
    "        for i in range(self.n_trees):\n",
    "            if i == 0:\n",
    "                tot = np.apply_along_axis(lambda x: self.get_pred(i, x), 1, X)\n",
    "            else:\n",
    "                res = np.apply_along_axis(lambda x: self.get_pred(i, x), 1, X)\n",
    "                tot = tot + res\n",
    "        tot = tot / self.n_trees\n",
    "        return tot\n",
    "    \n",
    "    def get_pred(self, i, pt, t = None):\n",
    "        if t == None:\n",
    "            t = self.trees[i]\n",
    "        if t.label == None:\n",
    "            if pt[t.feat] > t.thresh:\n",
    "                return self.get_pred(i, pt, t.right)\n",
    "            else:\n",
    "                return self.get_pred(i, pt, t.left)\n",
    "        else:\n",
    "            return t.label\n",
    "\n",
    "# You do not have to implement the following boost part, though it might help with Kaggle.\n",
    "class BoostedRandomForest(RandomForest):\n",
    "    def fit(self, X, y):\n",
    "        self.w = np.ones(X.shape[0]) / X.shape[0]  # Weights on data\n",
    "        self.a = np.zeros(self.n)  # Weights on decision trees\n",
    "        # TODO implement function\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO implement function\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(clf):\n",
    "    print(\"Cross validation:\")\n",
    "    cv_results = cross_validate(clf, X, y, cv=5, return_train_score=True)\n",
    "    train_results = cv_results['train_score']\n",
    "    test_results = cv_results['test_score']\n",
    "    avg_train_accuracy = sum(train_results) / len(train_results)\n",
    "    avg_test_accuracy = sum(test_results) / len(test_results)\n",
    "\n",
    "    print('averaged train accuracy:', avg_train_accuracy)\n",
    "    print('averaged validation accuracy:', avg_test_accuracy)\n",
    "    if hasattr(clf, \"decision_trees\"):\n",
    "        counter = Counter([t.tree_.feature[0] for t in clf.decision_trees])\n",
    "        first_splits = [\n",
    "            (features[term[0]], term[1]) for term in counter.most_common()\n",
    "        ]\n",
    "        print(\"First splits\", first_splits)\n",
    "\n",
    "    return avg_train_accuracy, avg_test_accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # dataset = \"titanic\"\n",
    "    dataset = \"spam\"\n",
    "    params = {\n",
    "        \"max_depth\": 5,\n",
    "        # \"random_state\": 6,\n",
    "        \"min_samples_leaf\": 10,\n",
    "    }\n",
    "    N = 100\n",
    "\n",
    "    if dataset == \"titanic\":\n",
    "        # Load titanic data       \n",
    "        path_train = 'datasets/titanic/titanic_training.csv'\n",
    "        data = genfromtxt(path_train, delimiter=',', dtype=None)\n",
    "        path_test = 'datasets/titanic/titanic_testing_data.csv'\n",
    "        test_data = genfromtxt(path_test, delimiter=',', dtype=None)\n",
    "        y = data[1:, 0]  # label = survived\n",
    "        class_names = [\"Died\", \"Survived\"]\n",
    "        \n",
    "        # TODO: preprocess titanic dataset\n",
    "        # Notes: \n",
    "        # 1. Some data points are missing their labels\n",
    "        # 2. Some features are not numerical but categorical\n",
    "        # 3. Some values are missing for some features\n",
    "\n",
    "    elif dataset == \"spam\":\n",
    "        features = [\n",
    "            \"pain\", \"private\", \"bank\", \"money\", \"drug\", \"spam\", \"prescription\",\n",
    "            \"creative\", \"height\", \"featured\", \"differ\", \"width\", \"other\",\n",
    "            \"energy\", \"business\", \"message\", \"volumes\", \"revision\", \"path\",\n",
    "            \"meter\", \"memo\", \"planning\", \"pleased\", \"record\", \"out\",\n",
    "            \"semicolon\", \"dollar\", \"sharp\", \"exclamation\", \"parenthesis\",\n",
    "            \"square_bracket\", \"ampersand\"\n",
    "        ]\n",
    "        assert len(features) == 32\n",
    "\n",
    "        # Load spam data\n",
    "        path_train = './datasets/spam_data/spam_data.mat'\n",
    "        data = scipy.io.loadmat(path_train)\n",
    "        X = data['training_data']\n",
    "        y = np.squeeze(data['training_labels'])\n",
    "        Z = data['test_data']\n",
    "        class_names = [\"Ham\", \"Spam\"]\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"Dataset %s not handled\" % dataset)\n",
    "\n",
    "    print(\"Features\", features)\n",
    "    print(\"Train/test size\", X.shape, Z.shape)\n",
    "\n",
    "    print(\"\\n\\nPart 0: constant classifier\")\n",
    "    print(\"Accuracy\", 1 - np.sum(y) / y.size)\n",
    "\n",
    "    # Basic decision tree\n",
    "    print('==================================================')\n",
    "    print(\"\\n\\nSimplified decision tree\")\n",
    "    dt = DecisionTree(max_depth=3, feature_labels=features)\n",
    "    dt.fit(X, y)\n",
    "    print(\"Predictions\", dt.predict(Z)[:100])\n",
    "    print(\"Tree structure\", dt.__repr__())\n",
    "\n",
    "    # TODO implement and evaluate remaining parts```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1cdaee-b03c-485b-9677-89834e044c82",
   "metadata": {},
   "source": [
    "### Q3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d8be03-fcd6-4db8-a4de-3bd95c2caf39",
   "metadata": {},
   "source": [
    "Refer to decision_tree_starter.py just above in section 3.1 for the random forest implementation. An example of the random forest training is given in section 3.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2438525b-fb67-4700-b5ba-3193eee1b739",
   "metadata": {},
   "source": [
    "### Q3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6152948a-1c7b-430b-ae87-36fe22648990",
   "metadata": {},
   "source": [
    "1. How did you deal with categorical features and missing values?  \n",
    "- I ran the categorical features through sklearn's DictVectorizer, and replaced empty values with nans. The DictVectorizer maintained these nan values, which were later filled in by sklearn's SimpleImputer, using a 'median' strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fe7de3-02ef-48fb-a7d1-64203cd04e86",
   "metadata": {},
   "source": [
    "2. What was your stopping criterion?  \n",
    "- I set a maximum depth for the tree. This was the stopping criterion, and artificially limited the tree's progress beyond this depth. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2c083-3136-4026-aa36-b8330837035b",
   "metadata": {},
   "source": [
    "3. How did you implement random forests?\n",
    "- I encapsulated the decision tree with a decision forest class which ran multiple instances of the decision tree, with a change that only subsets of features were selected at each stage, as well as subsets of the dataset. It then averaged the results of each of the individual decision trees, and rounded the result to 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a55e6a-4873-4d29-a653-f958a84ff100",
   "metadata": {},
   "source": [
    "4. Did you do anything special to speed up training?\n",
    "- My checking algortihm, which checks what the best split is, was initially checking a maximum of 20 linearly spaced splits between the highest and lowest value. For small nodes with, say, 2 points, this is a bad, wasteful technique. So, for nodes with less than 20 points, I started doing more efficient splitting, such that the nodes have minimal checking. This is done by only considering every possible split of points once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2cac46-60d7-43ac-9c9f-cf5a01a49918",
   "metadata": {},
   "source": [
    "5. Anything else cool you implemented?\n",
    "- Not particularly. I created my own tree printing code with `__str__`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622e6793-09e0-4ca1-a08f-f6e39cebbf2c",
   "metadata": {},
   "source": [
    "### Q3.4\n",
    "**SPAM + Decision Tree**  \n",
    "Here, we actually train the decision tree coded up in the previous steps. I start with the spam dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "2686ccb6-1e00-4b38-bc8c-286af667ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = io.loadmat(\"datasets/spam_data/prep_spam_data.mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fb0c87-c6fe-4488-9253-0ff7525d4596",
   "metadata": {},
   "source": [
    "Now, I import the decision tree starter file, and assign X, y (SPAM). I also set the seed to 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "e89843d6-037d-4420-b979-25efebbd595b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import decision_tree_starter as dt\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "ac31b68d-2a65-4776-97a0-46acd2a0c28b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = dset[\"training_data\"]\n",
    "y = dset[\"training_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "id": "ebfc2a0e-93db-4c7c-82d3-e2e8829671f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = dt.DecisionTree(max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "id": "a2f1d226-8bac-4ec3-ae42-6e2b023213cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.fit(X, y.T[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cffa27-64c1-4e0c-907b-f51143fdc84b",
   "metadata": {},
   "source": [
    "This is a printout of the decision tree and splits produced (SPAM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "id": "125219b8-a274-4bcf-8242-d0830e47d4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Feature x28 > 1.75'\n",
      "\t'Feature x28 > 0.05'\n",
      "\t\t'Feature x19 > 1.2'\n",
      "\t\t\t'Feature x19 > 0.05'\n",
      "\t\t\t\t'Leaf Label: None'\n",
      "\t\t\t\t\t'Leaf Label: 0'\n",
      "\t\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t\t'Leaf Label: 0'\n",
      "\t\t\t'Leaf Label: 0'\n",
      "\t\t'Feature x19 > 0.9'\n",
      "\t\t\t'Feature x15 > 0.3'\n",
      "\t\t\t\t'Feature x3 > 0.15'\n",
      "\t\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t\t'Feature x3 > 0.05'\n",
      "\t\t\t\t\t'Leaf Label: 0'\n",
      "\t\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t'Leaf Label: 0'\n",
      "\t'Feature x31 > 1.0'\n",
      "\t\t'Feature x19 > 0.9'\n",
      "\t\t\t'Feature x5 > 0.25'\n",
      "\t\t\t\t'Feature x15 > 2.2'\n",
      "\t\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t\t\t'Leaf Label: 0'\n",
      "\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t'Leaf Label: 0'\n",
      "\t\t'Feature x2 > 0.05'\n",
      "\t\t\t'Feature x6 > 1.0'\n",
      "\t\t\t\t'Feature x31 > 19.1'\n",
      "\t\t\t\t\t'Leaf Label: 0'\n",
      "\t\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t'Leaf Label: 1'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c88efa5-1101-4493-8010-ed58001ad4c4",
   "metadata": {},
   "source": [
    "**SPAM + DT Training Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "id": "75a8bf2a-6bcd-4ead-beb7-78fbd91167a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.88448525857902 %\n"
     ]
    }
   ],
   "source": [
    "pred = tree.predict(X)\n",
    "print(tree.accuracy(y.T[0], pred) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9166c0d5-7329-4ee3-9500-5f113b8efd0d",
   "metadata": {},
   "source": [
    "**SPAM + DT Validation Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "id": "174b0833-2405-40e0-a746-9a899b5d8f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xl = dset[\"valid_data\"]\n",
    "yl = dset[\"valid_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "2608d722-1ad2-4fcc-af5c-488945e035fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.62669245647969 %\n"
     ]
    }
   ],
   "source": [
    "pred2 = tree.predict(Xl)\n",
    "print(tree.accuracy(yl.T[0], pred2) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1abd04-6f96-4397-a7fc-233fd743db1e",
   "metadata": {},
   "source": [
    "**SPAM + Random Forest**  \n",
    "Here, we actually train the random forest coded up in the previous steps. I continue with the spam dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "id": "7a32862e-610c-416e-bd48-a03d2bc8a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = 100\n",
    "tree = dt.RandomForest(X, y.T[0], n_sub = 1500, n_trees = n_trees, n_subf = 8, max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "id": "6a4f9e2d-583c-4f81-95c7-fce3c2d71392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:32<00:00,  3.05it/s]\n"
     ]
    }
   ],
   "source": [
    "rforest = tree.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0693f94-d6f8-4595-bdf4-672f5992052e",
   "metadata": {},
   "source": [
    "**SPAM + RF Training Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "id": "1f9aaa5a-e478-4ad4-9500-533aeec3e625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.0961817303045 %\n"
     ]
    }
   ],
   "source": [
    "pred = np.round(tree.predict(X))\n",
    "print(tree.accuracy(y.T[0], pred) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c685a485-e368-4d13-b52d-fceb7ea1a18f",
   "metadata": {},
   "source": [
    "**SPAM + RF Validation Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "id": "150491e6-457c-4451-919a-a26267629c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xl = dset[\"valid_data\"]\n",
    "yl = dset[\"valid_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "id": "1715702e-45bb-4f30-9abf-a1f7b3b1b0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.94970986460348 %\n"
     ]
    }
   ],
   "source": [
    "pred2 = np.round(tree.predict(Xl))\n",
    "print(tree.accuracy(yl.T[0], pred2) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d462c2-6730-43a8-b29a-d194474b0b38",
   "metadata": {},
   "source": [
    "**Titanic + Decision Tree**  \n",
    "Now, I train the decision tree on the titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1456,
   "id": "bacb1b4c-a40f-4f94-b6ee-cf574fde8c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tset = io.loadmat(\"datasets/titanic/prep_titanic.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1457,
   "id": "299bbf86-3954-487c-b6d1-10446c3dff17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import decision_tree_starter as dt\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1458,
   "id": "55176ccc-8d19-4cfc-94c6-271385daa8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xt = tset[\"training_data\"]\n",
    "yt = tset[\"training_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1459,
   "id": "1c6649be-8cef-4470-9a03-51a5af8c4a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttree = dt.DecisionTree(max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1460,
   "id": "40d79fae-10c7-45be-8c14-91b54f9f0a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdtree = ttree.fit(Xt, yt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43793284-2ca4-48d9-91d7-23e446b2b5da",
   "metadata": {},
   "source": [
    "**Titanic + DT Training Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1461,
   "id": "ed82347c-7315-4269-a735-7f6d542f0188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.0 %\n"
     ]
    }
   ],
   "source": [
    "pred = ttree.predict(Xt)\n",
    "print(ttree.accuracy(yt[0], pred) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b073c2-bab0-446e-8a44-009b77edc1cb",
   "metadata": {},
   "source": [
    "**Titanic + DT Validation Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1462,
   "id": "921fd2b3-56f7-4e66-92be-faff451af978",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtl = tset[\"valid_data\"]\n",
    "ytl = tset[\"valid_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1463,
   "id": "a7cb966a-675b-4e35-be21-51bb358dc0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.39698492462311 %\n"
     ]
    }
   ],
   "source": [
    "pred2 = ttree.predict(Xtl)\n",
    "print(ttree.accuracy(ytl[0], pred2) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002b847-7578-45b6-828d-10a11b872207",
   "metadata": {},
   "source": [
    "__**Titanic + Random Forest**__  \n",
    "Here, we actually train the random forest coded up in the previous steps. I continue with the titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1464,
   "id": "c342ef95-9002-4267-83c7-b976f94ec7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_trees = 150\n",
    "tree = dt.RandomForest(Xt, yt[0], n_sub = 700, n_trees = n_trees, n_subf = 100, max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "id": "47d3dffc-c99f-40c3-b350-67490511a015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 150/150 [10:46<00:00,  4.31s/it]\n"
     ]
    }
   ],
   "source": [
    "rforest = tree.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8445e4a1-b2c2-4b8a-8b50-33e6d53b8a0c",
   "metadata": {},
   "source": [
    "**Titanic + RF Training Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1466,
   "id": "2ac2ac02-fa69-4bd9-a7a6-a3aa6c26154e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.25 %\n"
     ]
    }
   ],
   "source": [
    "pred = np.round(tree.predict(Xt))\n",
    "print(tree.accuracy(yt[0], pred) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1b3350-080b-4b81-a200-125c24e44096",
   "metadata": {},
   "source": [
    "**Titanic + RF Validation Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1467,
   "id": "bade3bd7-49da-4e95-8a3b-b7b6bea593e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtl = tset[\"valid_data\"]\n",
    "ytl = tset[\"valid_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "id": "3cfff967-d95a-4b1c-8434-3c3771f306e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.39 %\n"
     ]
    }
   ],
   "source": [
    "pred2 = np.round(tree.predict(Xtl))\n",
    "print(np.round(tree.accuracy(ytl[0], pred2) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cad966-806d-4def-8aff-fd5ebd55446c",
   "metadata": {},
   "source": [
    "**Submitting to Kaggle**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c293341b-6cb7-4501-bbd1-730067863d31",
   "metadata": {},
   "source": [
    "SPAM:  \n",
    "__Kaggle Score: 0.77650__  \n",
    "__Kaggle Username: Shrihan Agarwal__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "id": "fde593e8-e15f-49b7-bb67-5623c38835e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import decision_tree_starter as dt\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "id": "82d0c8ea-57ec-481e-9c44-26eababbaaa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = dset[\"training_data\"]\n",
    "y = dset[\"training_labels\"]\n",
    "Xsptest = dset[\"test_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "id": "78d58506-c66d-4ffc-89c2-3aebab53db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = dt.DecisionTree(max_depth = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "id": "819d2059-11a6-4e7b-ae3d-cffccb467ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.fit(X, y.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1362,
   "id": "71086d50-e183-48c4-9298-6d6d2d09355e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.34606089898502 %\n"
     ]
    }
   ],
   "source": [
    "pred = tree.predict(X)\n",
    "print(tree.accuracy(y.T[0], pred) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "id": "4475498e-583b-4dbd-a571-9ef3df9fc4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xl = dset[\"valid_data\"]\n",
    "yl = dset[\"valid_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1364,
   "id": "e6e5b44b-d90b-4d82-b083-73e4de4a90c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.59187620889749 %\n"
     ]
    }
   ],
   "source": [
    "pred2 = tree.predict(Xl)\n",
    "print(tree.accuracy(yl.T[0], pred2) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "id": "e42b5757-a744-4e98-bb13-21d47f7dee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tree.predict(Xsptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1366,
   "id": "f73c3f21-2d4b-44c7-bbeb-f4dbb2f1df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(range(1, len(pred) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1367,
   "id": "9397a39e-a2d3-48f5-af30-1c8e95889fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_csv = np.array(list(zip(idx, pred)), dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "id": "2441a689-4736-47cc-ad6e-c26d4b0857fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"shri_spam_rf.csv\", pre_csv, fmt = '%s', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558596c1-49c5-4208-8bdf-9262d5036f16",
   "metadata": {},
   "source": [
    "TITANIC:  \n",
    "__Kaggle Score: 0.79677__  \n",
    "__Kaggle Username: Shrihan Agarwal__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "id": "235bc25e-3604-41d4-8ae5-299ae9eb60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "Xfin = np.vstack([Xt, Xtl])\n",
    "yfin = np.concatenate([yt, ytl], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1470,
   "id": "5c6ef277-2f7b-424f-8d41-411d1a0233ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttree = dt.DecisionTree(max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1471,
   "id": "2531cf20-b2f4-4ae9-a00d-7fa77ea3f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdtree = ttree.fit(Xfin, yfin[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1472,
   "id": "e64382b0-2f8c-4e4a-9ac1-5ec5d05a9142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 1127)"
      ]
     },
     "execution_count": 1472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1473,
   "id": "23d95bd5-b3f1-4055-85f1-028871bad282",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ttree.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1474,
   "id": "2a454527-fbb3-452c-9b3f-06e03a79a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(range(1, len(pred) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1475,
   "id": "472ef4c6-64e3-4419-a526-0312a4abb81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_csv = np.array(list(zip(idx, pred)), dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1476,
   "id": "cca933ad-ceae-4527-a8f0-aa33428c10a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"shri_titanic_rf.csv\", pre_csv, fmt = '%s', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfbe468-c376-49fa-be90-e5ab8f246514",
   "metadata": {},
   "source": [
    "The Id,Category is added manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c8c533-d4d0-4a69-b75e-b05f71124a03",
   "metadata": {},
   "source": [
    "### Q3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff2375d-730f-4784-a5b1-ff72849c7927",
   "metadata": {},
   "source": [
    "#### Q3.5.1 \n",
    "Skipped, optional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a80e5-e47e-42ee-a5f7-8281a366df51",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Q3.5.2\n",
    "Here, we take two sample points for X, and trace their path through the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "id": "159d1840-a656-457e-8144-ff56ca575c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = dt.DecisionTree(max_depth = 5)\n",
    "dtree = tree.fit(X, y.T[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b8f1f7-5826-410e-9a25-b9885ab36994",
   "metadata": {},
   "source": [
    "With label 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "id": "9451c8cb-a892-430b-961e-740916452541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 989,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "id": "09ea49f2-a108-480f-b7c1-7de90760dda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 990,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "id": "6dd2cfb9-c8d2-4548-8372-608f9584a9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclamation <= 1.75\n",
      "exclamation > 0.05\n",
      "meter <= 0.9\n",
      "message <= 0.3\n",
      "money <= 0.15\n",
      "Classified as: 1 (HAM)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 991,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.trace_path_spam(X[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce5d074-f1ca-4a03-b93a-bc12e21bd977",
   "metadata": {},
   "source": [
    "With label 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "id": "903e1dd5-66db-417e-8bd8-360cb08f02a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 992,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "id": "6e59fc0c-450e-40d0-ae96-e17fc361371c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 2., 0., 0., 0., 0., 0., 0., 1., 3., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 993,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "id": "2616385f-e3d8-431d-80f7-8905eb18d4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclamation <= 1.75\n",
      "exclamation <= 0.05\n",
      "meter > 1.2\n",
      "Classified as: 0 (SPAM)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 995,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.trace_path_spam(X[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c70b594-effb-47cc-a2af-9477b745cba0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Q3.5.3\n",
    "Here, for the random forest, I find the most common first splits. I could not find the category labels chosen for this spaam dataset, as the featurizer.py used for generating this was not given to us. However, given the category labels chosen to make decisions, it would be a simple step to convert feature \"x19\" to \"money\", or whatever the actual category name is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "id": "7afd4655-49d4-4294-9164-9cec0d52911a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'decision_tree_starter' from '/Users/shri/Documents/Documents - Shrihan’s MacBook Air/CS189/hw5_release/hw5_code/decision_tree_starter.py'>"
      ]
     },
     "execution_count": 986,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(decision_tree_starter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "id": "4e3ff464-8b2b-472b-9060-4f1449d64cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls = decision_tree_starter.spam_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "id": "25879348-f84f-4599-a642-1806dbd03af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqdict = {}\n",
    "for i in range(n_trees):\n",
    "    a = rforest[i].__str__().split(\"\\n\")[0]\n",
    "    if a in freqdict:\n",
    "        freqdict[a] += 1\n",
    "    else:\n",
    "        freqdict[a] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "id": "9453a7d5-b158-4f25-bfc2-6b08c38315a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common First Splits in This Random Forest:\n",
      "exclamation >  1.0 (26 trees)\n",
      "meter >  0.9 (19 trees)\n",
      "money >  0.3 (15 trees)\n",
      "volumes >  0.45 (10 trees)\n",
      "ampersand >  0.95 (10 trees)\n",
      "pain >  0.1 (7 trees)\n",
      "prescription >  0.2 (5 trees)\n",
      "creative >  0.1 (3 trees)\n",
      "dollar >  1.75 (2 trees)\n",
      "spam >  0.25 (2 trees)\n",
      "featured >  0.15 (1 trees)\n"
     ]
    }
   ],
   "source": [
    "print(\"Most Common First Splits in This Random Forest:\")\n",
    "for i in sorted(list(freqdict.keys()), key = lambda x: freqdict[x], reverse = True):\n",
    "    j = i[1:-1]\n",
    "    k = int(i.split(\" >\")[0].split(\"x\")[1])\n",
    "    l = i.split(\" >\")[1].split(\"'\")[0]\n",
    "    print(lbls[k], \">\", l, \"(\" + str(freqdict[i]) + \" trees)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1243669a-2424-4451-8b34-e72281cebd0f",
   "metadata": {},
   "source": [
    "#### Q3.5.4\n",
    "I keep all hyperparameters fixed, and only change the depth, varying from 1 to 40, creating a new decision tree in each case. This results in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "id": "fcde530e-4c43-4e26-8f95-3c26b3bd6e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vacc(start = 1, stop = 40):\n",
    "    max_val = 0\n",
    "    max_depth = 0\n",
    "    i = np.arange(start, stop + 1)\n",
    "    accarr = []\n",
    "    for j in tqdm(i):\n",
    "        tree = dt.DecisionTree(j)\n",
    "        dtree = tree.fit(X, y.T[0])\n",
    "        pred = tree.predict(Xl)\n",
    "        acc = tree.accuracy(yl.T[0], pred)\n",
    "        accarr.append(acc)\n",
    "        if acc > max_val:\n",
    "            max_val = acc\n",
    "            max_depth = j\n",
    "    \n",
    "    plt.plot(i, accarr)\n",
    "    plt.title(\"Validation Accuracy vs. Depth\")\n",
    "    plt.xlabel(\"Validation Accuracy\")\n",
    "    plt.ylabel(\"Depth\")\n",
    "    return max_val, max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "id": "cd935dbd-9b55-4aff-a622-d71aad9313bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 40/40 [08:30<00:00, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Depth: 21\n",
      "Best Accuracy: 0.8278529980657641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "max_acc, max_depth = test_vacc(1, 40)\n",
    "print(\"Best Depth:\", max_depth)\n",
    "print(\"Best Accuracy:\", max_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0af53-9a0d-4b2f-9c37-df4f2d25a284",
   "metadata": {},
   "source": [
    "We see in the plot that the as the decision tree depth increases, the validation accuracy increases (slightly stochastically), due to better splitting of the dataset. However, beyond a certain depth, we see it level off and actually drop. This is because of overfitting. As the depth increases, overfitting of the tree causes the tree to be heavily dependent on outliers in the training data, which causes the validation accuracy to go down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cc809b-6adf-48c0-8b17-6a9dad7326f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Q3.6\n",
    "\n",
    "Titanic visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1538,
   "id": "f4e9b4cb-bd02-4ffe-9645-43fc1aae0b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'decision_tree_starter' from '/Users/shri/Documents/Documents - Shrihan’s MacBook Air/CS189/hw5_release/hw5_code/decision_tree_starter.py'>"
      ]
     },
     "execution_count": 1538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(decision_tree_starter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1539,
   "id": "22eeaee5-6245-4e7b-893c-db9bf3c42e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tset = io.loadmat(\"datasets/titanic/prep_titanic.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1524,
   "id": "a556ee4c-02a1-4163-a32c-d646d688da9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import decision_tree_starter as dt\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1525,
   "id": "244250f4-470b-42e9-8890-a4c82fe78332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xt = tset[\"training_data\"]\n",
    "yt = tset[\"training_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1545,
   "id": "2392fcfc-5233-46b6-b4c3-b400ce1ec158",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttree = dt.DecisionTree(max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1546,
   "id": "037395eb-ac2c-4bf5-9a64-20026daca369",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdtree = ttree.fit(Xt, yt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca76665c-e2d5-416b-b8f6-57082cfdb612",
   "metadata": {},
   "source": [
    "This is a printout of the decision tree and splits produced (Titanic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1547,
   "id": "736edbd3-6dc6-463e-92f6-f996cbee1c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'sex=female > 0.05'\n",
      "\t'age > 12.354194999999999'\n",
      "\t\t'sibsp > 1.0'\n",
      "\t\t\t'fare > 15.89999'\n",
      "\t\t\t\t'age > 0.74999'\n",
      "\t\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t\t\t'Leaf Label: 0'\n",
      "\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t'Leaf Label: 0'\n",
      "\t\t'pclass > 1.1'\n",
      "\t\t\t'age > 54.8'\n",
      "\t\t\t\t'cabin=C52 > 0.05'\n",
      "\t\t\t\t\t'Leaf Label: 0'\n",
      "\t\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t\t'age > 79.99999'\n",
      "\t\t\t\t\t'Leaf Label: 0'\n",
      "\t\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t'ticket=1601 > 0.05'\n",
      "\t\t\t\t'fare > 29.4'\n",
      "\t\t\t\t\t'Leaf Label: 0'\n",
      "\t\t\t\t\t'Leaf Label: 0'\n",
      "\t\t\t\t'age > 27.99999'\n",
      "\t\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t\t\t'Leaf Label: 1'\n",
      "\t'pclass > 2.0'\n",
      "\t\t'cabin=C22 C26 > 0.05'\n",
      "\t\t\t'cabin=C55 C57 > 0.05'\n",
      "\t\t\t\t'pclass > 1.05'\n",
      "\t\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t\t'Leaf Label: 0'\n",
      "\t\t\t'Leaf Label: 0'\n",
      "\t\t'fare > 22.599999999999998'\n",
      "\t\t\t'age > 16.558355'\n",
      "\t\t\t\t'fare > 21.07499'\n",
      "\t\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t\t\t'Leaf Label: 0'\n",
      "\t\t\t\t'fare > 7.720415'\n",
      "\t\t\t\t\t'Leaf Label: 1'\n",
      "\t\t\t\t\t'Leaf Label: 0'\n",
      "\t\t\t'ticket=347077 > 0.99999'\n",
      "\t\t\t\t'Leaf Label: 0'\n",
      "\t\t\t\t'Leaf Label: 1'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tdtree.strtitanic())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
